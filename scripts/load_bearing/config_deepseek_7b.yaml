Model:
  model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"  # The model name
  model_save_path: "./experiments/models"  # The path to save the model
  load_precision_mode: "4bits" # Options: ["4bits","8bits","full"]
  lora: true # false
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  lora_bias: "none" #sticking to example : https://huggingface.co/docs/trl/main/en/peft_integration

Inference:
  log_with: 'wandb'
  batch_size: 10
  seed: 42
  num_trials : 10
  is_peft_model: True
  load_lora_from_path_wandb: "avid-microwave-28_model_0_step_672"
  penalisation_class_kwargs:
    max_new_tokens_threshold: 900
    nouns_path: mars_steg/dataset/theory_of_mind_nouns.yaml
    nouns_penalisation_type: names
    temporal_reward_penalisation_offset: 0.022
    chance_penalisation: 0.99


Generation:
  min_length: 0
  # top_k: 0.0
  top_p: 0.95
  num_beams: 1
  temperature: 0.6
  do_sample: true
  #pad_token_id: 0
  bos_token_id: 151646
  eos_token_id: 151643
  max_new_tokens: 1024
  return_prompt: False
  generate_ref_response: False
  use_cache : True
